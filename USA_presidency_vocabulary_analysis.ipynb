{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USA presidency vocabulary analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPw04mkqr5gy+1pNNzKgkDU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamednihal/USA-presidency-vocabulary/blob/main/USA_presidency_vocabulary_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm67EXOJ8v2P"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JgpNSVqAu5F"
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ep2K3caFEWn"
      },
      "source": [
        "# get list of all speech files\n",
        "files = sorted([file for file in os.listdir() if file[-4:] == '.txt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9dG2h2kdp5G"
      },
      "source": [
        "import gensim\n",
        "import spacy\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enM6xSeUe1dY"
      },
      "source": [
        "read file function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoPnI5i6eiQX"
      },
      "source": [
        "def read_file(file_name):\n",
        "  with open(file_name, 'r+', encoding='utf-8') as file:\n",
        "    file_text = file.read()\n",
        "  return file_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgW4R2bwe-hx"
      },
      "source": [
        "speeches = [read_file(speech)for speech in files]\n",
        "speeches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shvG_bt1fOHc"
      },
      "source": [
        "len(speeches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGbDEGBsfskA"
      },
      "source": [
        "#preprocess each speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NllcWs_cfXl0"
      },
      "source": [
        "def process_speeches(speeches):\n",
        "  word_tokenized_speeches = list()\n",
        "  for speech in speeches:\n",
        "    sentence_tokenizer = PunktSentenceTokenizer()\n",
        "    sentence_tokenized_speech = sentence_tokenizer.tokenize(speech)\n",
        "    word_tokenized_sentences = list()\n",
        "    for sentence in sentence_tokenized_speech:\n",
        "      word_tokenized_sentence = [word.lower().strip('.').strip('?').strip('!') for word in sentence.replace(\",\",\"\").replace(\"-\",\" \").replace(\":\",\"\").split()]\n",
        "      word_tokenized_sentences.append(word_tokenized_sentence)\n",
        "    word_tokenized_speeches.append(word_tokenized_sentences)\n",
        "  return word_tokenized_speeches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQbHpuUTf3v1"
      },
      "source": [
        "processed_speeches = process_speeches(speeches)\n",
        "print(process_speeches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWPDYNGngGWs"
      },
      "source": [
        "#Merge speeches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQPFUHPYf8Tu"
      },
      "source": [
        "def merge_speeches(speeches):\n",
        "  all_sentences = list()\n",
        "  for speech in speeches:\n",
        "    for sentence in speech:\n",
        "      all_sentences.append(sentence)\n",
        "  return all_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_o2kbYfgK__"
      },
      "source": [
        "all_sentences = merge_speeches(processed_speeches)\n",
        "print(all_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EHPB476gY7c"
      },
      "source": [
        "#most frequent used words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BNNGrxcgQQA"
      },
      "source": [
        "def most_frequent_words(list_of_sentences):\n",
        "  all_words = [word for sentence in list_of_sentences for word in sentence]\n",
        "  return Counter(all_words).most_common()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWe3B4DCgcUF"
      },
      "source": [
        "most_freq_words = most_frequent_words(all_sentences)\n",
        "most_frequent_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHAJekw6g6s5"
      },
      "source": [
        "#create gensim model of all speeches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M8zWjWyg9rp"
      },
      "source": [
        "all_prez_embeddings = gensim.models.Word2Vec(all_sentences, size=96, window=5, min_count=1, workers=2, sg=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3T3ugijhViv"
      },
      "source": [
        "#Similar word to 'freedom'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acEbMg4ChFz7"
      },
      "source": [
        "# view words similar to freedom\n",
        "similar_to_freedom  = all_prez_embeddings.most_similar('freedom', topn= 20)\n",
        "print(similar_to_freedom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBxBrNGehHPv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}